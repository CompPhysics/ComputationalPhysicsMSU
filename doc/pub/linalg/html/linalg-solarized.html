<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Computational Physics  Lectures: Linear Algebra methods">

<title>Computational Physics  Lectures: Linear Algebra methods</title>


<link href="https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<link href="https://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #93a1a1;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #eee8d5;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/hplgit/doconce/master/bundled/html_images/small_yellow_question.png); }

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Important Matrix and vector handling packages',
               2,
               None,
               '___sec0'),
              ('Basic Matrix Features', 2, None, '___sec1'),
              ('Basic Matrix Features', 2, None, '___sec2'),
              ('Basic Matrix Features', 2, None, '___sec3'),
              ('Some famous Matrices', 2, None, '___sec4'),
              ('Basic Matrix Features', 2, None, '___sec5'),
              ('Important Mathematical Operations', 2, None, '___sec6'),
              ('Important Mathematical Operations', 2, None, '___sec7'),
              ('Important Mathematical Operations', 2, None, '___sec8'),
              ('Important Mathematical Operations', 2, None, '___sec9'),
              ('Matrix Handling in C/C++, Static and Dynamical allocation',
               2,
               None,
               '___sec10'),
              ('Matrix Handling in C/C++', 2, None, '___sec11'),
              ('Matrix Handling in C/C++', 2, None, '___sec12'),
              ('Matrix Handling in Fortran 90/95', 2, None, '___sec13'),
              ('Dynamic memory allocation in C/C++', 2, None, '___sec14'),
              ('Matrix Handling in C/C++, Dynamic Allocation',
               2,
               None,
               '___sec15'),
              ('Armadillo, recommended!!', 2, None, '___sec16'),
              ('Armadillo, simple examples', 2, None, '___sec17'),
              ('Armadillo, how to compile and install', 2, None, '___sec18'),
              ('Armadillo, simple examples', 2, None, '___sec19'),
              ('Armadillo, simple examples', 2, None, '___sec20'),
              ('Armadillo, simple examples', 2, None, '___sec21'),
              ('Armadillo, simple examples', 2, None, '___sec22'),
              ('Armadillo, simple examples', 2, None, '___sec23'),
              ('Armadillo, simple examples', 2, None, '___sec24'),
              ('Armadillo, simple examples', 2, None, '___sec25'),
              ('Gaussian Elimination', 2, None, '___sec26'),
              ('Gaussian Elimination', 2, None, '___sec27'),
              ('Gaussian Elimination', 2, None, '___sec28'),
              ('Gaussian Elimination', 2, None, '___sec29'),
              ('Gaussian Elimination', 2, None, '___sec30'),
              ('Gaussian Elimination', 2, None, '___sec31'),
              ('Gaussian Elimination', 2, None, '___sec32'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec33'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec34'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec35'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec36'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec37'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec38'),
              ('Backward substitution', 2, None, '___sec39'),
              ('Gaussian Elimination and Tridiagonal matrices, project 1',
               2,
               None,
               '___sec40'),
              ('Project 1, hints', 2, None, '___sec41'),
              ('Project 1, hints', 2, None, '___sec42'),
              ('Simple expressions for project 1', 2, None, '___sec43'),
              ('"Program '
               'example":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Projects/2016/Project1/Examples/TridiagonalSimple.cpp"',
               2,
               None,
               '___sec44'),
              ('Linear Algebra Methods', 2, None, '___sec45'),
              ('LU Decomposition', 2, None, '___sec46'),
              ('LU Decomposition', 2, None, '___sec47'),
              ('LU Decomposition, why?', 2, None, '___sec48'),
              ('LU Decomposition, linear equations', 2, None, '___sec49'),
              ('LU Decomposition, linear equations', 2, None, '___sec50'),
              ('LU Decomposition, why?', 2, None, '___sec51'),
              ('LU Decomposition, linear equations', 2, None, '___sec52'),
              ('LU Decomposition, the inverse of a matrix',
               2,
               None,
               '___sec53'),
              ('LU Decomposition, the inverse of a matrix',
               2,
               None,
               '___sec54'),
              ('LU Decomposition, the inverse', 2, None, '___sec55'),
              ('"How to use the Library '
               'functions":"https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/cppLibrary"',
               2,
               None,
               '___sec56'),
              ('"How to use the Library '
               'functions":"https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/cppLibrary"',
               2,
               None,
               '___sec57'),
              ('"How to use the Library '
               'functions":"https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/cppLibrary"',
               2,
               None,
               '___sec58'),
              ('"How to use the Library '
               'functions":"https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/FortranLibrary"',
               2,
               None,
               '___sec59'),
              ('"How to use the Library '
               'functions":"https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/FortranLibrary"',
               2,
               None,
               '___sec60'),
              ('"Using Armadillo to perform an LU '
               'decomposition":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/CppQtCodesLectures/MatrixTest/main.cpp"',
               2,
               None,
               '___sec61'),
              ('Iterative methods, Chapter 6', 2, None, '___sec62'),
              ("Iterative methods, Jacobi's method", 2, None, '___sec63'),
              ("Iterative methods, Jacobi's method", 2, None, '___sec64'),
              ("Iterative methods, Jacobi's method", 2, None, '___sec65'),
              ("Iterative methods, Gauss-Seidel's method", 2, None, '___sec66'),
              ("Iterative methods, Gauss-Seidel's method", 2, None, '___sec67'),
              ('Iterative methods, Successive over-relaxation',
               2,
               None,
               '___sec68'),
              ('Iterative methods, Successive over-relaxation',
               2,
               None,
               '___sec69'),
              ('Iterative methods, Successive over-relaxation',
               2,
               None,
               '___sec70'),
              ('Cubic Splines, Chapter 6', 2, None, '___sec71'),
              ('Splines', 2, None, '___sec72'),
              ('Splines', 2, None, '___sec73'),
              ('Splines', 2, None, '___sec74'),
              ('Splines', 2, None, '___sec75'),
              ('Splines', 2, None, '___sec76'),
              ('Splines', 2, None, '___sec77'),
              ('Splines', 2, None, '___sec78'),
              ('Splines', 2, None, '___sec79'),
              ('Splines', 2, None, '___sec80')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- ------------------- main content ---------------------- -->



<center><h1>Computational Physics  Lectures: Linear Algebra methods </h1></center>  <!-- document title -->

<p>
<!-- author(s): Morten Hjorth-Jensen -->

<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>

<p>
<!-- institution(s) -->

<center>[1] <b>Department of Physics, University of Oslo</b></center>
<center>[2] <b>Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University</b></center>
<br>
<p>
<center><h4>Jan 8, 2018</h4></center> <!-- date -->
<br>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec0">Important Matrix and vector handling packages </h2>

<p>
The Numerical Recipes codes have been rewritten in Fortran 90/95 and
C/C++ by us.  The original source codes are taken from the widely used
software package LAPACK, which follows two other popular packages
developed in the 1970s, namely EISPACK and LINPACK.

<ul>
  <li> LINPACK: package for linear equations and least square problems.</li>
  <li> LAPACK:package for solving symmetric, unsymmetric and generalized eigenvalue problems. From LAPACK's website <a href="http://www.netlib.org" target="_blank"><tt>http://www.netlib.org</tt></a> it is possible to download for free all source codes from this library. Both C/C++ and Fortran versions are available.</li>
  <li> BLAS (I, II and III): (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations. Blas I is vector operations, II vector-matrix operations and III matrix-matrix operations. Highly parallelized and efficient codes, all available for download from <a href="http://www.netlib.org" target="_blank"><tt>http://www.netlib.org</tt></a>.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec1">Basic Matrix Features </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Matrix properties reminder.</b>
<p>
$$
 \mathbf{A} =
      \begin{bmatrix} a_{11} & a_{12} & a_{13} & a_{14} \\
                                 a_{21} & a_{22} & a_{23} & a_{24} \\
                                   a_{31} & a_{32} & a_{33} & a_{34} \\
                                  a_{41} & a_{42} & a_{43} & a_{44}
             \end{bmatrix}\qquad
\mathbf{I} =
      \begin{bmatrix} 1 & 0 & 0 & 0 \\
                                 0 & 1 & 0 & 0 \\
                                 0 & 0 & 1 & 0 \\
                                 0 & 0 & 0 & 1
             \end{bmatrix}
$$
</div>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec2">Basic Matrix Features </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
The inverse of a matrix is defined by

$$
\mathbf{A}^{-1} \cdot \mathbf{A} = I
$$
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec3">Basic Matrix Features </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Matrix Properties Reminder.</b>
<p>

<p>
<table border="1">
<thead>
<tr><th align="center">                Relations                 </th> <th align="center">      Name     </th> <th align="center">                              matrix elements                              </th> </tr>
</thead>
<tbody>
<tr><td align="center">   \( A = A^{T} \)                               </td> <td align="center">   symmetric          </td> <td align="center">   \( a_{ij} = a_{ji} \)                                                          </td> </tr>
<tr><td align="center">   \( A = \left (A^{T} \right )^{-1} \)          </td> <td align="center">   real orthogonal    </td> <td align="center">   \( \sum_k a_{ik} a_{jk} = \sum_k a_{ki} a_{kj} = \delta_{ij} \)                </td> </tr>
<tr><td align="center">   \( A = A^{ * } \)                             </td> <td align="center">   real matrix        </td> <td align="center">   \( a_{ij} = a_{ij}^{ * } \)                                                    </td> </tr>
<tr><td align="center">   \( A = A^{\dagger} \)                         </td> <td align="center">   hermitian          </td> <td align="center">   \( a_{ij} = a_{ji}^{ * } \)                                                    </td> </tr>
<tr><td align="center">   \( A = \left (A^{\dagger} \right )^{-1} \)    </td> <td align="center">   unitary            </td> <td align="center">   \( \sum_k a_{ik} a_{jk}^{ * } = \sum_k a_{ki}^{ * } a_{kj} = \delta_{ij} \)    </td> </tr>
</tbody>
</table>

</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec4">Some famous Matrices </h2>

<ul>
  <li> Diagonal if \( a_{ij}=0 \) for \( i\ne j \)</li>
  <li> Upper triangular if \( a_{ij}=0 \) for \( i > j \)</li>
  <li> Lower triangular if \( a_{ij}=0 \) for \( i < j \)</li>
  <li> Upper Hessenberg if \( a_{ij}=0 \) for \( i > j+1 \)</li>
  <li> Lower Hessenberg if \( a_{ij}=0 \) for \( i < j+1 \)</li>
  <li> Tridiagonal if \( a_{ij}=0 \) for \( |i -j| > 1 \)</li>
  <li> Lower banded with bandwidth \( p \): \( a_{ij}=0 \) for \( i > j+p \)</li>
  <li> Upper banded with bandwidth \( p \): \( a_{ij}=0 \) for \( i < j+p \)</li>
  <li> Banded, block upper triangular, block lower triangular....</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec5">Basic Matrix Features </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Some Equivalent Statements.</b>
<p>
For an \( N\times N \) matrix  \( \mathbf{A} \) the following properties are all equivalent

<ul>
  <li> If the inverse of \( \mathbf{A} \) exists, \( \mathbf{A} \) is nonsingular.</li>
  <li> The equation \( \mathbf{Ax}=0 \) implies \( \mathbf{x}=0 \).</li>
  <li> The rows of \( \mathbf{A} \) form a basis of \( R^N \).</li>
  <li> The columns of \( \mathbf{A} \) form a basis of \( R^N \).</li>
  <li> \( \mathbf{A} \) is a product of elementary matrices.</li>
  <li> \( 0 \) is not eigenvalue of \( \mathbf{A} \).</li>
</ul>
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec6">Important Mathematical Operations </h2>

<p>
The basic matrix operations that we will deal with are addition and subtraction

$$
\begin{equation}
\mathbf{A}= \mathbf{B}\pm\mathbf{C}  \Longrightarrow a_{ij} = b_{ij}\pm c_{ij},
\label{eq:mtxadd}
\end{equation}
$$

scalar-matrix multiplication

$$
\begin{equation}
\mathbf{A}= \gamma\mathbf{B}  \Longrightarrow a_{ij} = \gamma b_{ij},
\label{_auto1}
\end{equation}
$$

vector-matrix multiplication

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec7">Important Mathematical Operations </h2>
$$
\begin{equation}
\mathbf{y}=\mathbf{Ax}   \Longrightarrow y_{i} = \sum_{j=1}^{n} a_{ij}x_j,
\label{eq:vecmtx}
\end{equation}
$$

matrix-matrix multiplication

$$
\begin{equation}
\mathbf{A}=\mathbf{BC}   \Longrightarrow a_{ij} = \sum_{k=1}^{n} b_{ik}c_{kj},
\label{eq:mtxmtx}
\end{equation}
$$

and transposition

$$
\begin{equation}
\mathbf{A}=\mathbf{B}^T   \Longrightarrow a_{ij} = b_{ji}
\label{_auto2}
\end{equation}
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec8">Important Mathematical Operations </h2>

<p>
Similarly, important vector operations that we will deal with are addition and subtraction

$$
\begin{equation}
\mathbf{x}= \mathbf{y}\pm\mathbf{z}  \Longrightarrow x_{i} = y_{i}\pm z_{i},
\label{_auto3}
\end{equation}
$$

scalar-vector multiplication

$$
\begin{equation}
\mathbf{x}= \gamma\mathbf{y}  \Longrightarrow x_{i} = \gamma y_{i},
\label{_auto4}
\end{equation}
$$

vector-vector multiplication (called Hadamard multiplication)
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec9">Important Mathematical Operations </h2>
$$
\begin{equation}
\mathbf{x}=\mathbf{yz}   \Longrightarrow x_{i} = y_{i}z_i,
\label{_auto5}
\end{equation}
$$

the inner or so-called dot product  resulting in a constant

$$
\begin{equation}
x=\mathbf{y}^T\mathbf{z}   \Longrightarrow x = \sum_{j=1}^{n} y_{j}z_{j},
\label{eq:innerprod}
\end{equation}
$$

and the outer product, which yields a matrix,

$$
\begin{equation}
\mathbf{A}=  \mathbf{yz}^T \Longrightarrow  a_{ij} = y_{i}z_{j},
\label{eq:outerprod}
\end{equation}
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec10">Matrix Handling in C/C++, Static and Dynamical allocation </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Static.</b>
<p>
We have  an \( N\times N \) matrix A  with \( N=100 \)
In C/C++ this would be  defined as

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>   <span style="color: #00688B; font-weight: bold">int</span> N = <span style="color: #B452CD">100</span>;
   <span style="color: #00688B; font-weight: bold">double</span> A[<span style="color: #B452CD">100</span>][<span style="color: #B452CD">100</span>];
   <span style="color: #228B22">//   initialize all elements to zero</span>
   <span style="color: #8B008B; font-weight: bold">for</span>(i=<span style="color: #B452CD">0</span> ; i &lt; N ; i++) {
      <span style="color: #8B008B; font-weight: bold">for</span>(j=<span style="color: #B452CD">0</span> ; j &lt; N ; j++) {
         A[i][j] = <span style="color: #B452CD">0.0</span>;
</pre></div>
<p>
Note the way the matrix is organized, row-major order.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec11">Matrix Handling in C/C++ </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Row Major Order, Addition.</b>
<p>
We have  \( N\times N \) matrices A, B and C and we wish to
evaluate \( A=B+C \).

$$
\mathbf{A}= \mathbf{B}\pm\mathbf{C}  \Longrightarrow a_{ij} = b_{ij}\pm c_{ij},
$$

In C/C++ this would be coded like

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>   <span style="color: #8B008B; font-weight: bold">for</span>(i=<span style="color: #B452CD">0</span> ; i &lt; N ; i++) {
      <span style="color: #8B008B; font-weight: bold">for</span>(j=<span style="color: #B452CD">0</span> ; j &lt; N ; j++) {
         a[i][j] = b[i][j]+c[i][j]
</pre></div>

</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec12">Matrix Handling in C/C++ </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Row Major Order, Multiplication.</b>
<p>
We have  \( N\times N \) matrices A, B and C and we wish to
evaluate \( A=BC \).

$$
\mathbf{A}=\mathbf{BC}   \Longrightarrow a_{ij} = \sum_{k=1}^{n} b_{ik}c_{kj},
$$

In C/C++ this would be coded like

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>   <span style="color: #8B008B; font-weight: bold">for</span>(i=<span style="color: #B452CD">0</span> ; i &lt; N ; i++) {
      <span style="color: #8B008B; font-weight: bold">for</span>(j=<span style="color: #B452CD">0</span> ; j &lt; N ; j++) {
         <span style="color: #8B008B; font-weight: bold">for</span>(k=<span style="color: #B452CD">0</span> ; k &lt; N ; k++) {
            a[i][j]+=b[i][k]*c[k][j];
</pre></div>

</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec13">Matrix Handling in Fortran 90/95 </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Column Major Order.</b>
<p>
<p>

<!-- code=fortran (!bc fcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>   <span style="color: #8B008B; font-weight: bold">ALLOCATE</span> (a(N,N), b(N,N), c(N,N))
   <span style="color: #8B008B; font-weight: bold">DO </span>j=<span style="color: #B452CD">1</span>,  N
      <span style="color: #8B008B; font-weight: bold">DO </span>i=<span style="color: #B452CD">1</span>, N
         a(i,j)=b(i,j)+c(i,j)
      ENDDO
   ENDDO
   ...
   <span style="color: #8B008B; font-weight: bold">DEALLOCATE</span>(a,b,c)
</pre></div>
<p>
Fortran 90 writes the above statements in a much simpler way

<p>

<!-- code=fortran (!bc fcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>   a=b+c
</pre></div>
<p>
Multiplication

<p>

<!-- code=fortran (!bc fcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>   a=<span style="color: #658b00">MATMUL</span>(b,c)
</pre></div>
<p>
Fortran contains also the intrinsic functions TRANSPOSE and CONJUGATE.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec14">Dynamic memory allocation in C/C++ </h2>

<p>
At least three possibilities in this course

<ul>
  <li> Do it yourself</li>
  <li> Use the functions provided in the library package lib.cpp</li>
  <li> Use Armadillo <a href="http://arma.sourceforgenet" target="_blank"><tt>http://arma.sourceforgenet</tt></a> (a C++ linear algebra library, discussion both here and at lab).</li> 
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec15">Matrix Handling in C/C++, Dynamic Allocation </h2>

<p>
<div class="alert alert-block alert-block alert-text-normal">
<b>Do it yourself.</b>
<p>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span><span style="color: #00688B; font-weight: bold">int</span> N;
<span style="color: #00688B; font-weight: bold">double</span> **  A;
A = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span>*[N]
<span style="color: #8B008B; font-weight: bold">for</span> ( i = <span style="color: #B452CD">0</span>; i &lt; N; i++)
    A[i] = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span>[N];
</pre></div>
<p>
Always free space when you don't need an array anymore.

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span><span style="color: #8B008B; font-weight: bold">for</span> ( i = <span style="color: #B452CD">0</span>; i &lt; N; i++)
    <span style="color: #8B008B; font-weight: bold">delete</span>[] A[i];
<span style="color: #8B008B; font-weight: bold">delete</span>[] A;
</pre></div>

</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec16">Armadillo, recommended!! </h2>

<ul>
  <li> Armadillo is a C++ linear algebra library (matrix maths) aiming towards a good balance between speed and ease of use. The syntax is deliberately similar to Matlab.</li>
  <li> Integer, floating point and complex numbers are supported, as well as a subset of trigonometric and statistics functions. Various matrix decompositions are provided through optional integration with LAPACK, or one of its high performance drop-in replacements (such as the multi-threaded MKL or ACML libraries).</li>
  <li> A delayed evaluation approach is employed (at compile-time) to combine several operations into one and reduce (or eliminate) the need for temporaries. This is accomplished through recursive templates and template meta-programming.</li>
  <li> Useful for conversion of research code into production environments, or if C++ has been decided as the language of choice, due to speed and/or integration capabilities.</li>
  <li> The library is open-source software, and is distributed under a license that is useful in both open-source and commercial/proprietary contexts.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec17">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iostream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;armadillo&gt;</span><span style="color: #1e889b"></span>

<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> std;
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> arma;

<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span>(<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span>** argv)
  {
  mat A = randu&lt;mat&gt;(<span style="color: #B452CD">5</span>,<span style="color: #B452CD">5</span>);
  mat B = randu&lt;mat&gt;(<span style="color: #B452CD">5</span>,<span style="color: #B452CD">5</span>);

  cout &lt;&lt; A*B &lt;&lt; endl;

  <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec18">Armadillo, how to compile and install </h2>

<p>
For people using Ubuntu, Debian, Linux Mint, simply go to the synaptic package manager and install
armadillo from there.
You may have to install Lapack as well.
For Mac and Windows users, follow the instructions from the webpage
<a href="http://arma.sourceforge.net" target="_blank"><tt>http://arma.sourceforge.net</tt></a>.
To compile, use for example (linux/ubuntu)

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>c++ -O2 -o program.x program.cpp  -larmadillo -llapack -lblas
</pre></div>
<p>
where the <code>-l</code> option indicates the library you wish to link to.

<p>
For OS X users you may have to declare the paths to the include files and the libraries as
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>c++ -O2 -o program.x program.cpp  -L/usr/local/lib -I/usr/local/include -larmadillo -llapack -lblas
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec19">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iostream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&quot;armadillo&quot;</span><span style="color: #1e889b"></span>
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> arma;
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> std;

<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span>(<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span>** argv)
  {
  <span style="color: #228B22">// directly specify the matrix size (elements are uninitialised)</span>
  mat A(<span style="color: #B452CD">2</span>,<span style="color: #B452CD">3</span>);
  <span style="color: #228B22">// .n_rows = number of rows    (read only)</span>
  <span style="color: #228B22">// .n_cols = number of columns (read only)</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;A.n_rows = &quot;</span> &lt;&lt; A.n_rows &lt;&lt; endl;
  cout &lt;&lt; <span style="color: #CD5555">&quot;A.n_cols = &quot;</span> &lt;&lt; A.n_cols &lt;&lt; endl;
  <span style="color: #228B22">// directly access an element (indexing starts at 0)</span>
  A(<span style="color: #B452CD">1</span>,<span style="color: #B452CD">2</span>) = <span style="color: #B452CD">456.0</span>;
  A.print(<span style="color: #CD5555">&quot;A:&quot;</span>);
  <span style="color: #228B22">// scalars are treated as a 1x1 matrix,</span>
  <span style="color: #228B22">// hence the code below will set A to have a size of 1x1</span>
  A = <span style="color: #B452CD">5.0</span>;
  A.print(<span style="color: #CD5555">&quot;A:&quot;</span>);
  <span style="color: #228B22">// if you want a matrix with all elements set to a particular value</span>
  <span style="color: #228B22">// the .fill() member function can be used</span>
  A.set_size(<span style="color: #B452CD">3</span>,<span style="color: #B452CD">3</span>);
  A.fill(<span style="color: #B452CD">5.0</span>);  A.print(<span style="color: #CD5555">&quot;A:&quot;</span>);
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec20">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  mat B;

  <span style="color: #228B22">// endr indicates &quot;end of row&quot;</span>
  B &lt;&lt; <span style="color: #B452CD">0.555950</span> &lt;&lt; <span style="color: #B452CD">0.274690</span> &lt;&lt; <span style="color: #B452CD">0.540605</span> &lt;&lt; <span style="color: #B452CD">0.798938</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.108929</span> &lt;&lt; <span style="color: #B452CD">0.830123</span> &lt;&lt; <span style="color: #B452CD">0.891726</span> &lt;&lt; <span style="color: #B452CD">0.895283</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.948014</span> &lt;&lt; <span style="color: #B452CD">0.973234</span> &lt;&lt; <span style="color: #B452CD">0.216504</span> &lt;&lt; <span style="color: #B452CD">0.883152</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.023787</span> &lt;&lt; <span style="color: #B452CD">0.675382</span> &lt;&lt; <span style="color: #B452CD">0.231751</span> &lt;&lt; <span style="color: #B452CD">0.450332</span> &lt;&lt; endr;

  <span style="color: #228B22">// print to the cout stream</span>
  <span style="color: #228B22">// with an optional string before the contents of the matrix</span>
  B.print(<span style="color: #CD5555">&quot;B:&quot;</span>);

  <span style="color: #228B22">// the &lt;&lt; operator can also be used to print the matrix</span>
  <span style="color: #228B22">// to an arbitrary stream (cout in this case)</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;B:&quot;</span> &lt;&lt; endl &lt;&lt; B &lt;&lt; endl;
  <span style="color: #228B22">// save to disk</span>
  B.save(<span style="color: #CD5555">&quot;B.txt&quot;</span>, raw_ascii);
  <span style="color: #228B22">// load from disk</span>
  mat C;
  C.load(<span style="color: #CD5555">&quot;B.txt&quot;</span>);
  C += <span style="color: #B452CD">2.0</span> * B;
  C.print(<span style="color: #CD5555">&quot;C:&quot;</span>);
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec21">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  <span style="color: #228B22">// submatrix types:</span>
  <span style="color: #228B22">//</span>
  <span style="color: #228B22">// .submat(first_row, first_column, last_row, last_column)</span>
  <span style="color: #228B22">// .row(row_number)</span>
  <span style="color: #228B22">// .col(column_number)</span>
  <span style="color: #228B22">// .cols(first_column, last_column)</span>
  <span style="color: #228B22">// .rows(first_row, last_row)</span>

  cout &lt;&lt; <span style="color: #CD5555">&quot;C.submat(0,0,3,1) =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; C.submat(<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>,<span style="color: #B452CD">3</span>,<span style="color: #B452CD">1</span>) &lt;&lt; endl;

  <span style="color: #228B22">// generate the identity matrix</span>
  mat D = eye&lt;mat&gt;(<span style="color: #B452CD">4</span>,<span style="color: #B452CD">4</span>);

  D.submat(<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>,<span style="color: #B452CD">3</span>,<span style="color: #B452CD">1</span>) = C.cols(<span style="color: #B452CD">1</span>,<span style="color: #B452CD">2</span>);
  D.print(<span style="color: #CD5555">&quot;D:&quot;</span>);

  <span style="color: #228B22">// transpose</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;trans(B) =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; trans(B) &lt;&lt; endl;

  <span style="color: #228B22">// maximum from each column (traverse along rows)</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;max(B) =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; max(B) &lt;&lt; endl;
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec22">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  <span style="color: #228B22">// maximum from each row (traverse along columns)</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;max(B,1) =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; max(B,<span style="color: #B452CD">1</span>) &lt;&lt; endl;
  <span style="color: #228B22">// maximum value in B</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;max(max(B)) = &quot;</span> &lt;&lt; max(max(B)) &lt;&lt; endl;
  <span style="color: #228B22">// sum of each column (traverse along rows)</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;sum(B) =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; sum(B) &lt;&lt; endl;
  <span style="color: #228B22">// sum of each row (traverse along columns)</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;sum(B,1) =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; sum(B,<span style="color: #B452CD">1</span>) &lt;&lt; endl;
  <span style="color: #228B22">// sum of all elements</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;sum(sum(B)) = &quot;</span> &lt;&lt; sum(sum(B)) &lt;&lt; endl;
  cout &lt;&lt; <span style="color: #CD5555">&quot;accu(B)     = &quot;</span> &lt;&lt; accu(B) &lt;&lt; endl;
  <span style="color: #228B22">// trace = sum along diagonal</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;trace(B)    = &quot;</span> &lt;&lt; trace(B) &lt;&lt; endl;
  <span style="color: #228B22">// random matrix -- values are uniformly distributed in the [0,1] interval</span>
  mat E = randu&lt;mat&gt;(<span style="color: #B452CD">4</span>,<span style="color: #B452CD">4</span>);
  E.print(<span style="color: #CD5555">&quot;E:&quot;</span>);
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec23">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  <span style="color: #228B22">// row vectors are treated like a matrix with one row</span>
  rowvec r;
  r &lt;&lt; <span style="color: #B452CD">0.59499</span> &lt;&lt; <span style="color: #B452CD">0.88807</span> &lt;&lt; <span style="color: #B452CD">0.88532</span> &lt;&lt; <span style="color: #B452CD">0.19968</span>;
  r.print(<span style="color: #CD5555">&quot;r:&quot;</span>);

  <span style="color: #228B22">// column vectors are treated like a matrix with one column</span>
  colvec q;
  q &lt;&lt; <span style="color: #B452CD">0.81114</span> &lt;&lt; <span style="color: #B452CD">0.06256</span> &lt;&lt; <span style="color: #B452CD">0.95989</span> &lt;&lt; <span style="color: #B452CD">0.73628</span>;
  q.print(<span style="color: #CD5555">&quot;q:&quot;</span>);

  <span style="color: #228B22">// dot or inner product</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;as_scalar(r*q) = &quot;</span> &lt;&lt; as_scalar(r*q) &lt;&lt; endl;

    <span style="color: #228B22">// outer product</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;q*r =&quot;</span> &lt;&lt; endl;
  cout &lt;&lt; q*r &lt;&lt; endl;


  <span style="color: #228B22">// sum of three matrices (no temporary matrices are created)</span>
  mat F = B + C + D;
  F.print(<span style="color: #CD5555">&quot;F:&quot;</span>);

    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec24">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iostream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&quot;armadillo&quot;</span><span style="color: #1e889b"></span>
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> arma;
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> std;

<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span>(<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span>** argv)
  {
  cout &lt;&lt; <span style="color: #CD5555">&quot;Armadillo version: &quot;</span> &lt;&lt; arma_version::as_string() &lt;&lt; endl;

  mat A;

  A &lt;&lt; <span style="color: #B452CD">0.165300</span> &lt;&lt; <span style="color: #B452CD">0.454037</span> &lt;&lt; <span style="color: #B452CD">0.995795</span> &lt;&lt; <span style="color: #B452CD">0.124098</span> &lt;&lt; <span style="color: #B452CD">0.047084</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.688782</span> &lt;&lt; <span style="color: #B452CD">0.036549</span> &lt;&lt; <span style="color: #B452CD">0.552848</span> &lt;&lt; <span style="color: #B452CD">0.937664</span> &lt;&lt; <span style="color: #B452CD">0.866401</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.348740</span> &lt;&lt; <span style="color: #B452CD">0.479388</span> &lt;&lt; <span style="color: #B452CD">0.506228</span> &lt;&lt; <span style="color: #B452CD">0.145673</span> &lt;&lt; <span style="color: #B452CD">0.491547</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.148678</span> &lt;&lt; <span style="color: #B452CD">0.682258</span> &lt;&lt; <span style="color: #B452CD">0.571154</span> &lt;&lt; <span style="color: #B452CD">0.874724</span> &lt;&lt; <span style="color: #B452CD">0.444632</span> &lt;&lt; endr
    &lt;&lt; <span style="color: #B452CD">0.245726</span> &lt;&lt; <span style="color: #B452CD">0.595218</span> &lt;&lt; <span style="color: #B452CD">0.409327</span> &lt;&lt; <span style="color: #B452CD">0.367827</span> &lt;&lt; <span style="color: #B452CD">0.385736</span> &lt;&lt; endr;

  A.print(<span style="color: #CD5555">&quot;A =&quot;</span>);

  <span style="color: #228B22">// determinant</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;det(A) = &quot;</span> &lt;&lt; det(A) &lt;&lt; endl;
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec25">Armadillo, simple examples </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  <span style="color: #228B22">// inverse</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;inv(A) = &quot;</span> &lt;&lt; endl &lt;&lt; inv(A) &lt;&lt; endl;
  <span style="color: #00688B; font-weight: bold">double</span> k = <span style="color: #B452CD">1.23</span>;

  mat    B = randu&lt;mat&gt;(<span style="color: #B452CD">5</span>,<span style="color: #B452CD">5</span>);
  mat    C = randu&lt;mat&gt;(<span style="color: #B452CD">5</span>,<span style="color: #B452CD">5</span>);

  rowvec r = randu&lt;rowvec&gt;(<span style="color: #B452CD">5</span>);
  colvec q = randu&lt;colvec&gt;(<span style="color: #B452CD">5</span>);


  <span style="color: #228B22">// examples of some expressions</span>
  <span style="color: #228B22">// for which optimised implementations exist</span>
  <span style="color: #228B22">// optimised implementation of a trinary expression</span>
  <span style="color: #228B22">// that results in a scalar</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;as_scalar( r*inv(diagmat(B))*q ) = &quot;</span>;
  cout &lt;&lt; as_scalar( r*inv(diagmat(B))*q ) &lt;&lt; endl;

  <span style="color: #228B22">// example of an expression which is optimised</span>
  <span style="color: #228B22">// as a call to the dgemm() function in BLAS:</span>
  cout &lt;&lt; <span style="color: #CD5555">&quot;k*trans(B)*C = &quot;</span> &lt;&lt; endl &lt;&lt; k*trans(B)*C;

    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec26">Gaussian Elimination </h2>

<p>
We start with the linear set of equations

$$
   \mathbf{A}\mathbf{x} = \mathbf{w}.
$$

We assume also that the matrix \( \mathbf{A} \) is non-singular and that the
matrix elements along the diagonal satisfy \( a_{ii} \ne 0 \). Simple \( 4\times 4  \) example

$$
\begin{bmatrix}
                           a_{11}& a_{12} &a_{13}& a_{14}\\
                           a_{21}& a_{22} &a_{23}& a_{24}\\
                           a_{31}& a_{32} &a_{33}& a_{34}\\
                           a_{41}& a_{42} &a_{43}& a_{44}\\
                      \end{bmatrix} \begin{bmatrix}
                           x_1\\
                           x_2\\
                           x_3 \\
                           x_4  \\
                      \end{bmatrix}
  =\begin{bmatrix}
                           w_1\\
                           w_2\\
                           w_3 \\
                           w_4\\
                      \end{bmatrix}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec27">Gaussian Elimination </h2>
or

$$
\begin{align}
 a_{11}x_1 +a_{12}x_2 +a_{13}x_3 + a_{14}x_4=&w_1 \nonumber \\
a_{21}x_1 + a_{22}x_2 + a_{23}x_3 + a_{24}x_4=&w_2 \nonumber \\
a_{31}x_1 + a_{32}x_2 + a_{33}x_3 + a_{34}x_4=&w_3 \nonumber \\
a_{41}x_1 + a_{42}x_2 + a_{43}x_3 + a_{44}x_4=&w_4. \nonumber
\end{align}
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec28">Gaussian Elimination </h2>

<p>
The basic idea of Gaussian elimination is to use the first equation to eliminate the first unknown \( x_1 \)
from the remaining \( n-1 \) equations. Then we use the new second equation to eliminate the second unknown
\( x_2 \) from the remaining \( n-2 \) equations. With \( n-1 \) such eliminations
we obtain a so-called upper triangular set of equations of the form

$$
\begin{align}
 b_{11}x_1 +b_{12}x_2 +b_{13}x_3 + b_{14}x_4=&y_1 \nonumber \\
 b_{22}x_2 + b_{23}x_3 + b_{24}x_4=&y_2 \nonumber \\
b_{33}x_3 + b_{34}x_4=&y_3 \nonumber \\
b_{44}x_4=&y_4. \nonumber
\label{eq:gaussbacksub}
\end{align}
$$

We can solve this system of equations recursively starting from \( x_n \) (in our case \( x_4 \)) and proceed with
what is called a backward substitution.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec29">Gaussian Elimination </h2>
This process can be expressed mathematically as

$$
\begin{equation}
   x_m = \frac{1}{b_{mm}}\left(y_m-\sum_{k=m+1}^nb_{mk}x_k\right)\quad m=n-1,n-2,\dots,1.
\label{_auto6}
\end{equation}
$$

To arrive at such an upper triangular system of equations, we start by eliminating
the unknown \( x_1 \) for \( j=2,n \). We achieve this by multiplying the first equation by \( a_{j1}/a_{11} \) and then subtract
the result from the $j$th equation. We assume obviously that \( a_{11}\ne 0 \) and that
\( \mathbf{A} \) is not singular.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec30">Gaussian Elimination </h2>

<p>
Our actual \( 4\times 4 \) example reads after the first operation

$$
\begin{bmatrix}
                           a_{11}& a_{12} &a_{13}& a_{14}\\
                           0& (a_{22}-\frac{a_{21}a_{12}}{a_{11}}) &(a_{23}-\frac{a_{21}a_{13}}{a_{11}}) & (a_{24}-\frac{a_{21}a_{14}}{a_{11}})\\
0& (a_{32}-\frac{a_{31}a_{12}}{a_{11}})& (a_{33}-\frac{a_{31}a_{13}}{a_{11}})& (a_{34}-\frac{a_{31}a_{14}}{a_{11}})\\
0&(a_{42}-\frac{a_{41}a_{12}}{a_{11}}) &(a_{43}-\frac{a_{41}a_{13}}{a_{11}}) & (a_{44}-\frac{a_{41}a_{14}}{a_{11}}) \\
                      \end{bmatrix} \begin{bmatrix}
                           x_1\\
                           x_2\\
                           x_3 \\
                           x_4  \\
                      \end{bmatrix} 
  =\begin{bmatrix}
                           y_1\\
                           w_2^{(2)}\\
                           w_3^{(2)} \\
                           w_4^{(2)}\\
                      \end{bmatrix},
$$

or

$$
\begin{align}
 b_{11}x_1 +b_{12}x_2 +b_{13}x_3 + b_{14}x_4=&y_1 \nonumber \\
 a^{(2)}_{22}x_2 + a^{(2)}_{23}x_3 + a^{(2)}_{24}x_4=&w^{(2)}_2 \nonumber \\
 a^{(2)}_{32}x_2 + a^{(2)}_{33}x_3 + a^{(2)}_{34}x_4=&w^{(2)}_3 \nonumber \\
 a^{(2)}_{42}x_2 + a^{(2)}_{43}x_3 + a^{(2)}_{44}x_4=&w^{(2)}_4, \nonumber \\
\label{_auto7}
\end{align}
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec31">Gaussian Elimination </h2>

<p>
The new coefficients are

$$
\begin{equation}
   b_{1k} = a_{1k}^{(1)} \quad k=1,\dots,n,
\label{_auto8}
\end{equation}
$$

where each \( a_{1k}^{(1)} \) is equal to the original \( a_{1k} \) element. The other coefficients are

$$
\begin{equation}
a_{jk}^{(2)} = a_{jk}^{(1)}-\frac{a_{j1}^{(1)}a_{1k}^{(1)}}{a_{11}^{(1)}} \quad j,k=2,\dots,n,
\label{_auto9}
\end{equation}
$$

with a new right-hand side given by

$$
\begin{equation}
y_{1}=w_1^{(1)}, \quad w_j^{(2)} =w_j^{(1)}-\frac{a_{j1}^{(1)}w_1^{(1)}}{a_{11}^{(1)}} \quad j=2,\dots,n.
\label{_auto10}
\end{equation}
$$

We have also set \( w_1^{(1)}=w_1 \), the original vector element.
We see that the system of unknowns \( x_1,\dots,x_n \) is transformed into an \( (n-1)\times (n-1) \) problem.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec32">Gaussian Elimination </h2>

<p>
This step is called forward substitution.
Proceeding with these substitutions, we obtain the
general expressions for the new coefficients

$$
\begin{equation}
   a_{jk}^{(m+1)} = a_{jk}^{(m)}-\frac{a_{jm}^{(m)}a_{mk}^{(m)}}{a_{mm}^{(m)}} \quad j,k=m+1,\dots,n,
\label{_auto11}
\end{equation}
$$

with \( m=1,\dots,n-1 \) and a
right-hand side given by

$$
\begin{equation}
   w_j^{(m+1)} =w_j^{(m)}-\frac{a_{jm}^{(m)}w_m^{(m)}}{a_{mm}^{(m)}}\quad j=m+1,\dots,n.
\label{_auto12}
\end{equation}
$$

This set of \( n-1 \) elimations leads us to an equations which is solved by back substitution.
If the arithmetics is exact and the matrix \( \mathbf{A} \) is not singular, then the computed answer will be exact.

<p>
Even though the matrix elements along the diagonal are not zero,
numerically small numbers may appear and subsequent divisions may lead to large numbers, which, if added
to a small number may yield losses of precision. Suppose for example that our first division in \( (a_{22}-a_{21}a_{12}/a_{11}) \)
results in \( -10^{-7} \) and that \( a_{22} \) is one.
one. We are then
adding \( 10^7+1 \). With single precision this results in \( 10^7 \).

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec33">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
Suppose we want to solve the following boundary value equation

$$
  -\frac{d^2u(x)}{dx^2} = f(x,u(x)),
$$

with \( x\in (a,b) \) and with boundary conditions \( u(a)=u(b) = 0 \).
We assume that \( f \) is a continuous function in the domain \( x\in (a,b) \).
Since, except the few cases where it is possible to find analytic solutions, we
will seek after approximate solutions, we choose to represent the approximation to the second derivative
from the previous chapter

$$
  f''=\frac{f_h -2f_0 +f_{-h}}{h^2} +O(h^2).
$$

We subdivide our interval \( x\in (a,b) \) into \( n \) subintervals by setting \( x_i = ih \), with \( i=0,1,\dots,n+1 \).
The step size is then given by \( h=(b-a)/(n+1) \) with \( n\in {\mathbb{N}} \).
For the internal grid points \( i=1,2,\dots n \) we replace the differential operator with the above formula
resulting in

$$
u''(x_i) \approx  \frac{u(x_i+h) -2u(x_i) +u(x_i-h)}{h^2},
$$

which we rewrite as

$$
u^{''}_i \approx  \frac{u_{i+1} -2u_i +u_{i-i}}{h^2}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec34">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
We can rewrite our original differential equation in terms of a discretized equation with approximations to the
derivatives as

$$
    -\frac{u_{i+1} -2u_i +u_{i-i}}{h^2}=f(x_i,u(x_i)),
$$

with \( i=1,2,\dots, n \). We need to add to this system the two boundary conditions \( u(a) =u_0 \) and \( u(b) = u_{n+1} \).
If we define a matrix

$$
    \mathbf{A} = \frac{1}{h^2}\begin{bmatrix}
                          2 & -1 &  &   &  & \\
                          -1 & 2 & -1 & & & \\
                           & -1 & 2 & -1 & &  \\
                           & \dots   & \dots &\dots   &\dots & \dots \\
                           &   &  &-1  &2& -1 \\
                           &    &  &   &-1 & 2 \\
                      \end{bmatrix}
$$

and the corresponding vectors \( \mathbf{u} = (u_1, u_2, \dots,u_n)^T \) and
\( \mathbf{f}(\mathbf{u}) = f(x_1,x_2,\dots, x_n,u_1, u_2, \dots,u_n)^T \)  we can rewrite the differential equation
including the boundary conditions as a system of linear equations with  a large number of unknowns

$$
   \mathbf{A}\mathbf{u} = \mathbf{f}(\mathbf{u}).
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec35">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
We start with the linear set of equations

$$
   \mathbf{A}\mathbf{u} = \mathbf{f},
$$

where \( \mathbf{A} \) is a tridiagonal matrix which we rewrite as

$$
    \mathbf{A} = \begin{bmatrix}
                           b_1& c_1 & 0 &\dots   & \dots &\dots \\
                           a_2 & b_2 & c_2 &\dots &\dots &\dots \\
                           & a_3 & b_3 & c_3 & \dots & \dots \\
                           & \dots   & \dots &\dots   &\dots & \dots \\
                           &   &  &a_{n-1}  &b_{n-1}& c_{n-1} \\
                           &    &  &   &a_n & b_n \\
                      \end{bmatrix} 
$$

where \( a,b,c \) are one-dimensional arrays of length \( 1:n \).
In project 1 the arrays \( a \) and \( c \) are equal, namely \( a_i=c_i=-1/h^2 \).
The matrix is  also positive definite.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec36">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
We can rewrite as

$$
    \mathbf{A} = \begin{bmatrix}
                           b_1& c_1 & 0 &\dots   & \dots &\dots \\
                           a_2 & b_2 & c_2 &\dots &\dots &\dots \\
                           & a_3 & b_3 & c_3 & \dots & \dots \\
                           & \dots   & \dots &\dots   &\dots & \dots \\
                           &   &  &a_{n-1}  &b_{n-1}& c_{n-1} \\
                           &    &  &   &a_n & b_n \\
                      \end{bmatrix} \begin{bmatrix}
                           u_1\\
                           u_2\\
                           \dots \\
                          \dots  \\
                          \dots \\
                           u_n\\
                      \end{bmatrix} 
  =\begin{bmatrix}
                           f_1\\
                           f_2\\
                           \dots \\
                           \dots \\
                          \dots \\
                           f_n\\
                      \end{bmatrix}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec37">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
A tridiagonal matrix is a special form of banded matrix where all the elements are zero except for
those on and immediately above and below the leading diagonal.
The above tridiagonal system   can be written as

$$
  a_iu_{i-1}+b_iu_i+c_iu_{i+1} = f_i,
$$

for \( i=1,2,\dots,n \). We see that \( u_{-1} \) and \( u_{n+1} \) are not required and we can set \( a_1=c_n=0 \).
In many applications the matrix is symmetric and we have \( a_i=c_i \).
The algorithm for solving this set of equations is rather simple and requires two steps only,
a forward substitution and a backward substitution. These steps are also
common to the algorithms based on
Gaussian elimination that
we discussed previously. However, due to its simplicity, the number of floating point operations
is in this
case proportional with \( O(n) \) while Gaussian elimination requires \( 2n^3/3+O(n^2) \) floating point operations.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec38">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
In case your system of equations leads to a tridiagonal matrix, it is clearly an overkill to employ
Gaussian elimination or the standard LU decomposition.

<p>
Our algorithm starts with forward substitution with a loop over of the elements \( i \) and gives an update of the diagonal elements \( b_i \)
given by the new diagonals \( \tilde{b}_i \)
$$
\tilde{b}_i= b_i - \frac{a_ic_{i-1}}{\tilde{b}_{i-1}},
$$

and the new righthand side \( \tilde{f}_i \) given by
$$
\tilde{f}_i= f_i - \frac{a_i\tilde{f}_{i-1}}{\tilde{b}_{i-1}}.
$$

Recall that \( \tilde{b}_1=b_1 \) and \( \tilde{f}_1=f_1 \) always.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec39">Backward substitution </h2>

<p>
The backward substitution gives then the final solution
$$
u_{i-1}= \frac{\tilde{f}_{i-1}-c_{i-1}u_i}{\tilde{b}_{i-1}},
$$

with \( u_n=\tilde{f}_{n}/\tilde{b}_{n} \) when \( i=n \), the last point.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec40">Gaussian Elimination and Tridiagonal matrices, project 1 </h2>

<p>
The matrix \( \mathbf{A} \) which rephrases a second derivative in a discretized form is much simpler than the general matrix
$$
    \mathbf{A} = \begin{bmatrix}
                          2 & -1 & 0 & 0  &0  & 0\\
                          -1 & 2 & -1 &0 &0 &0 \\
                          0 & -1 & 2 & -1 & 0& 0 \\
                          0 & \dots   & \dots & \dots   &\dots & \dots \\
                          0 &0   &0  &-1  &2& -1 \\
                          0 &  0  &0  &0   &-1 & 2 \\
                      \end{bmatrix}.
$$

This matrix fulfills the condition of a weak dominance of the diagonal, with
\( |b_1| > |c_1| \), \( |b_n| > |a_n| \) and  \( |b_k| \ge |a_k|+|c_k| \) for \( k=2,3,\dots,n-1 \).
This is a relevant but not sufficient condition to guarantee that the matrix \( \mathbf{A} \) yields a solution to a linear
equation problem. The matrix needs also to be irreducible. A tridiagonal irreducible matrix means that all the elements \( a_i \) and
\( c_i \) are non-zero. If these two conditions are present, then \( \mathbf{A} \) is nonsingular and has a unique LU decomposition.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec41">Project 1, hints </h2>

<p>
When setting up the algo it is useful to note that the different
operations on the matrix (here as a \( 4\times 4 \) case  with diagonals
\( d_i \) and off-diagonals \( e_i \)) give is an extremely simple algorithm, namely
$$
   \begin{bmatrix}
                          d_1 & e_1 & 0 & 0 \\
                          e_2 & d_2 & e_2 & 0 \\
                          0 & e_3 & d_3 & e_3 \\
                          0 & 0 & e_4 & d_4
                      \end{bmatrix}\rightarrow
                 \begin{bmatrix}
                          d_1 & e_1 & 0 & 0 \\
                          0 & \tilde{d}_2 & e_2 & 0 \\
                          0 & e_3 & d_3 & e_3 \\
                          0 & 0 & e_4 & d_4
                      \end{bmatrix}\rightarrow
                \begin{bmatrix}
                          d_1 & e_1 & 0 & 0 \\
                          0 & \tilde{d}_2 & e_2 & 0 \\
                          0 & 0 & \tilde{d}_3 & e_3 \\
                          0 & 0 & e_4 & d_4
                      \end{bmatrix}
$$

and finally

$$
                      \begin{bmatrix}
                          d_1 & e_1 & 0 & 0 \\
                          0 & \tilde{d}_2 & e_2 & 0 \\
                          0 & 0 & \tilde{d}_3 & e_3 \\
                          0 & 0 & 0 & \tilde{d}_4
                      \end{bmatrix}
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec42">Project 1, hints </h2>

<p>
We notice the sub-blocks which get repeated

$$
   \begin{bmatrix}
                          d_1 & e_1 & 0 & 0 \\
                          0 & \tilde{d}_2 & e_2 & 0 \\
                          0 & 0 & \tilde{d}_3 & e_3 \\
                          0 & 0 & 0 & \tilde{d}_4
                      \end{bmatrix}
$$

The matrices we often end up with in rewriting for for example partial differential equations,
have the feature that all leading principal submatrices are non-singular.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec43">Simple expressions for project 1 </h2>
For the special matrix we can can actually precalculate the updated matrix elements \( \tilde{d}_i \). The non-diagonal elements \( e_i \) are unchanged.
For our particular matrix in project 1 we have 
$$
\tilde{d}_i= 2 - \frac{1}{\tilde{d}_{i-1}}=\frac{i+1}{i},
$$

and the new righthand side \( \tilde{f}_i \) given by
$$
\tilde{f}_i= f_i + \frac{(i-1)\tilde{f}_{i-1}}{i}.
$$

Recall that \( \tilde{d}_1=2 \) and \( \tilde{f}_1=f_1 \).  These arrays can be set up before computing \( u \).

<p>
The backward substitution gives then the final solution
$$
u_{i-1}= \frac{i-1}{i}\left(\tilde{f}_{i-1}+u_i\right),
$$

with \( u_n=\tilde{f}_{n}/\tilde{b}_{n} \).

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec44"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Projects/2016/Project1/Examples/TridiagonalSimple.cpp" target="_blank">Program example</a> </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iostream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;fstream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iomanip&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cmath&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;string&gt;</span><span style="color: #1e889b"></span>
<span style="color: #228B22">// use namespace for output and input</span>
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> std;

<span style="color: #228B22">// object for output files</span>
ofstream ofile;
<span style="color: #228B22">// Functions used</span>
<span style="color: #8B008B; font-weight: bold">inline</span> <span style="color: #00688B; font-weight: bold">double</span> <span style="color: #008b45">f</span>(<span style="color: #00688B; font-weight: bold">double</span> x){<span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">100.0</span>*exp(-<span style="color: #B452CD">10.0</span>*x);
}
<span style="color: #8B008B; font-weight: bold">inline</span> <span style="color: #00688B; font-weight: bold">double</span> <span style="color: #008b45">exact</span>(<span style="color: #00688B; font-weight: bold">double</span> x) {<span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">1.0</span>-(<span style="color: #B452CD">1</span>-exp(-<span style="color: #B452CD">10</span>))*x-exp(-<span style="color: #B452CD">10</span>*x);}

<span style="color: #228B22">// Begin main program</span>
<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span>(<span style="color: #00688B; font-weight: bold">int</span> argc, <span style="color: #00688B; font-weight: bold">char</span> *argv[]){
  <span style="color: #00688B; font-weight: bold">int</span> exponent; 
    string filename;
    <span style="color: #228B22">// We read also the basic name for the output file and the highest power of 10^n we want</span>
    <span style="color: #8B008B; font-weight: bold">if</span>( argc &lt;= <span style="color: #B452CD">1</span> ){
          cout &lt;&lt; <span style="color: #CD5555">&quot;Bad Usage: &quot;</span> &lt;&lt; argv[<span style="color: #B452CD">0</span>] &lt;&lt;
              <span style="color: #CD5555">&quot; read also file name on same line and max power 10^n&quot;</span> &lt;&lt; endl;
          exit(<span style="color: #B452CD">1</span>);
    }
        <span style="color: #8B008B; font-weight: bold">else</span>{
        filename = argv[<span style="color: #B452CD">1</span>]; <span style="color: #228B22">// first command line argument after name of program</span>
        exponent = atoi(argv[<span style="color: #B452CD">2</span>]);
    }
    <span style="color: #228B22">// Loop over powers of 10</span>
    <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i = <span style="color: #B452CD">1</span>; i &lt;= exponent; i++){
      <span style="color: #00688B; font-weight: bold">int</span>  n = (<span style="color: #00688B; font-weight: bold">int</span>) pow(<span style="color: #B452CD">10.0</span>,i);
      <span style="color: #228B22">// Declare new file name</span>
      string fileout = filename;
      <span style="color: #228B22">// Convert the power 10^i to a string</span>
      string argument = to_string(i);
      <span style="color: #228B22">// Final filename as filename-i-</span>
      fileout.append(argument);
      <span style="color: #00688B; font-weight: bold">double</span> h = <span style="color: #B452CD">1.0</span>/(n);
      <span style="color: #00688B; font-weight: bold">double</span> hh = h*h;
      <span style="color: #228B22">// Set up arrays for the simple case</span>
      <span style="color: #00688B; font-weight: bold">double</span> *d = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span> [n+<span style="color: #B452CD">1</span>]; <span style="color: #00688B; font-weight: bold">double</span> *b = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span> [n+<span style="color: #B452CD">1</span>]; <span style="color: #00688B; font-weight: bold">double</span> *solution = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span> [n+<span style="color: #B452CD">1</span>];
      <span style="color: #00688B; font-weight: bold">double</span> *x = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span>[n+<span style="color: #B452CD">1</span>];
      <span style="color: #228B22">// Quick setup of updated diagonal elements and value of</span>
      d[<span style="color: #B452CD">0</span>] = d[n] = <span style="color: #B452CD">2</span>; solution[<span style="color: #B452CD">0</span>] = solution[n] = <span style="color: #B452CD">0.0</span>;
      <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i = <span style="color: #B452CD">1</span>; i &lt; n; i++) d[i] = (i+<span style="color: #B452CD">1.0</span>)/( (<span style="color: #00688B; font-weight: bold">double</span>) i);  
      <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i = <span style="color: #B452CD">0</span>; i &lt;= n; i++){
	x[i]= i*h;
        b[i] = hh*f(i*h);
      }
      <span style="color: #228B22">// Forward substitution</span>
      <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i = <span style="color: #B452CD">2</span>; i &lt; n; i++) b[i] = b[i] + b[i-<span style="color: #B452CD">1</span>]/d[i-<span style="color: #B452CD">1</span>];
      <span style="color: #228B22">// Backward substitution</span>
      solution[n-<span style="color: #B452CD">1</span>] = b[n-<span style="color: #B452CD">1</span>]/d[n-<span style="color: #B452CD">1</span>];
      <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i = n-<span style="color: #B452CD">2</span>; i &gt; <span style="color: #B452CD">0</span>; i--) solution[i] = (b[i]+solution[i+<span style="color: #B452CD">1</span>])/d[i];
      ofile.open(fileout);
      ofile &lt;&lt; setiosflags(ios::showpoint | ios::uppercase);
      <span style="color: #228B22">//      ofile &lt;&lt; &quot;       x:             approx:          exact:       relative error&quot; &lt;&lt; endl;</span>
      <span style="color: #8B008B; font-weight: bold">for</span> (<span style="color: #00688B; font-weight: bold">int</span> i = <span style="color: #B452CD">1</span>; i &lt; n;i++) {
	<span style="color: #00688B; font-weight: bold">double</span> xval = x[i];
 	 <span style="color: #00688B; font-weight: bold">double</span> RelativeError = fabs((exact(xval)-solution[i])/exact(xval));
         ofile &lt;&lt; setw(<span style="color: #B452CD">15</span>) &lt;&lt; setprecision(<span style="color: #B452CD">8</span>) &lt;&lt; xval;
         ofile &lt;&lt; setw(<span style="color: #B452CD">15</span>) &lt;&lt; setprecision(<span style="color: #B452CD">8</span>) &lt;&lt; solution[i];
         ofile &lt;&lt; setw(<span style="color: #B452CD">15</span>) &lt;&lt; setprecision(<span style="color: #B452CD">8</span>) &lt;&lt; exact(xval);
         ofile &lt;&lt; setw(<span style="color: #B452CD">15</span>) &lt;&lt; setprecision(<span style="color: #B452CD">8</span>) &lt;&lt; log10(RelativeError) &lt;&lt; endl;
      }
      ofile.close();
      <span style="color: #8B008B; font-weight: bold">delete</span> [] x; <span style="color: #8B008B; font-weight: bold">delete</span> [] d; <span style="color: #8B008B; font-weight: bold">delete</span> [] b; <span style="color: #8B008B; font-weight: bold">delete</span> [] solution;
    }
    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
}
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec45">Linear Algebra Methods </h2>

<ul>
  <li> Gaussian elimination, \( O(2/3n^3) \) flops, general matrix</li>
  <li> LU decomposition, upper triangular and lower tridiagonal matrices, \( O(2/3n^3) \) flops, general matrix. Get easily the inverse, determinant and can solve linear equations with back-substitution only, \( O(n^2) \) flops</li>
  <li> Cholesky decomposition. Real symmetric or hermitian positive definite matrix, \( O(1/3n^3) \) flops.</li>
  <li> Tridiagonal linear systems, important for differential equations. Normally positive definite and non-singular. \( O(8n) \) flops for symmetric. Special case of banded matrices.</li>
  <li> Singular value decomposition</li>
  <li> the QR method will be discussed in chapter 7 in connection with eigenvalue systems. \( O(4/3n^3) \) flops.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec46">LU Decomposition </h2>

<p>
The LU decomposition method means that we can rewrite
this matrix as the product of two matrices \( \mathbf{L} \) and \( \mathbf{U} \)
where

$$
   \begin{bmatrix}
                          a_{11} & a_{12} & a_{13} & a_{14} \\
                          a_{21} & a_{22} & a_{23} & a_{24} \\
                          a_{31} & a_{32} & a_{33} & a_{34} \\
                          a_{41} & a_{42} & a_{43} & a_{44}
                      \end{bmatrix}
                      = \begin{bmatrix}
                              1  & 0      & 0      & 0 \\
                          l_{21} & 1      & 0      & 0 \\
                          l_{31} & l_{32} & 1      & 0 \\
                          l_{41} & l_{42} & l_{43} & 1
                      \end{bmatrix}
                        \begin{bmatrix}
                          u_{11} & u_{12} & u_{13} & u_{14} \\
                               0 & u_{22} & u_{23} & u_{24} \\
                               0 & 0      & u_{33} & u_{34} \\
                               0 & 0      &  0     & u_{44}
             \end{bmatrix}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec47">LU Decomposition </h2>

<p>
LU decomposition forms the backbone of other algorithms in linear algebra, such as the
solution of linear equations given by

$$
\begin{align}
 a_{11}x_1 +a_{12}x_2 +a_{13}x_3 + a_{14}x_4=&w_1 \nonumber \\
a_{21}x_1 + a_{22}x_2 + a_{23}x_3 + a_{24}x_4=&w_2 \nonumber \\
a_{31}x_1 + a_{32}x_2 + a_{33}x_3 + a_{34}x_4=&w_3 \nonumber \\
a_{41}x_1 + a_{42}x_2 + a_{43}x_3 + a_{44}x_4=&w_4.  \nonumber
\end{align}
$$

The above set of equations is conveniently solved by using LU decomposition as an intermediate step.

<p>
The matrix \( \mathbf{A}\in \mathbb{R}^{n\times n} \) has an LU factorization if the determinant
is different from zero. If the LU factorization exists and \( \mathbf{A} \) is non-singular, then the LU factorization
is unique and the determinant is given by

$$
det\{\mathbf{A}\}=det\{\mathbf{LU}\}= det\{\mathbf{L}\}det\{\mathbf{U}\}=u_{11}u_{22}\dots u_{nn}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec48">LU Decomposition, why? </h2>

<p>
There are at least three main advantages with LU decomposition compared with standard Gaussian elimination:

<ul>
  <li> It is straightforward to compute the determinant of a matrix</li>
  <li> If we have to solve sets of linear equations with the same matrix but with different vectors \( \mathbf{y} \), the number of FLOPS is of the order \( n^3 \).</li>
  <li> The inverse is such an operation</li> 
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec49">LU Decomposition, linear equations </h2>

<p>
With the LU decomposition it is rather
simple to solve a system of linear equations

$$
\begin{align}
 a_{11}x_1 +a_{12}x_2 +a_{13}x_3 + a_{14}x_4=&w_1 \nonumber \\
a_{21}x_1 + a_{22}x_2 + a_{23}x_3 + a_{24}x_4=&w_2 \nonumber \\
a_{31}x_1 + a_{32}x_2 + a_{33}x_3 + a_{34}x_4=&w_3 \nonumber \\
a_{41}x_1 + a_{42}x_2 + a_{43}x_3 + a_{44}x_4=&w_4. \nonumber
\end{align}
$$

<p>
This can be written in matrix form as

$$ \mathbf{Ax}=\mathbf{w}. $$

<p>
where \( \mathbf{A} \) and \( \mathbf{w} \) are known and we have to solve for
\( \mathbf{x} \). Using the LU dcomposition we write

$$ \mathbf{A} \mathbf{x} \equiv \mathbf{L} \mathbf{U} \mathbf{x} =\mathbf{w}. $$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec50">LU Decomposition, linear equations </h2>

<p>
The previous equation can be calculated in two steps

$$ \mathbf{L} \mathbf{y} = \mathbf{w};\qquad \mathbf{Ux}=\mathbf{y}. $$

<p>
To show that this is correct we use to the LU decomposition
to rewrite our system of linear equations as

$$  \mathbf{LUx}=\mathbf{w}, $$

and since the determinat of \( \mathbf{L} \) is equal to 1 (by construction
since the diagonals of \( \mathbf{L} \) equal 1) we can use the inverse of
\( \mathbf{L} \) to obtain

$$
   \mathbf{Ux}=\mathbf{L^{-1}w}=\mathbf{y},
$$

which yields the intermediate step

$$
   \mathbf{L^{-1}w}=\mathbf{y}
$$

and as soon as we have \( \mathbf{y} \) we can obtain \( \mathbf{x} \)
through \( \mathbf{Ux}=\mathbf{y} \).

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec51">LU Decomposition, why? </h2>

<p>
For our four-dimentional example this takes the form

$$
\begin{align}
 y_1=&w_1 \nonumber\\
l_{21}y_1 + y_2=&w_2\nonumber \\
l_{31}y_1 + l_{32}y_2 + y_3 =&w_3\nonumber \\
l_{41}y_1 + l_{42}y_2 + l_{43}y_3 + y_4=&w_4. \nonumber
\end{align}
$$

<p>
and

$$
\begin{align}
 u_{11}x_1 +u_{12}x_2 +u_{13}x_3 + u_{14}x_4=&y_1 \nonumber\\
u_{22}x_2 + u_{23}x_3 + u_{24}x_4=&y_2\nonumber \\
u_{33}x_3 + u_{34}x_4=&y_3\nonumber \\
u_{44}x_4=&y_4  \nonumber
\end{align}
$$

<p>
This example shows the basis for the algorithm
needed to solve the set of \( n \) linear equations.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec52">LU Decomposition, linear equations </h2>

<p>
The algorithm goes as follows

<ul>
  <li> Set up the matrix \( \bf A \) and the vector \( \bf w \) with their correct dimensions. This determines the dimensionality of the unknown vector \( \bf x \).</li>
  <li> Then LU decompose the matrix \( \bf A \) through a call to the function <code>ludcmp(double a, int n, int indx, double &d)</code>. This functions returns the LU decomposed matrix \( \bf A \), its determinant and the vector indx which keeps track of the number of interchanges of rows. If the determinant is zero, the solution is malconditioned.</li>
  <li> Thereafter you call the function  <code>lubksb(double a, int n, int indx, double w)</code> which uses the LU decomposed matrix \( \bf A \) and the vector \( \bf w \) and returns \( \bf x \) in the same place as \( \bf w \). Upon exit the original content in \( \bf w \) is destroyed. If you wish to keep this information, you should make a backup of it in your calling function.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec53">LU Decomposition, the inverse of a matrix </h2>

<p>
If the inverse exists then

$$
   \mathbf{A}^{-1}\mathbf{A}=\mathbf{I},
$$

the identity matrix. With an LU decomposed matrix we can rewrite the last equation as

$$
   \mathbf{LU}\mathbf{A}^{-1}=\mathbf{I}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec54">LU Decomposition, the inverse of a matrix </h2>

<p>
If we assume that the first column (that is column 1) of the inverse matrix
can be written as a vector with unknown entries

$$
    \mathbf{A}_1^{-1}= \begin{bmatrix}
                              a_{11}^{-1} \\
                              a_{21}^{-1} \\
                              \dots \\
                              a_{n1}^{-1} \\
                    \end{bmatrix},
$$

then we have a linear set of equations

$$
    \mathbf{LU}\begin{bmatrix}
                              a_{11}^{-1} \\
                              a_{21}^{-1} \\
                              \dots \\
                              a_{n1}^{-1} \\
                    \end{bmatrix} =\begin{bmatrix}
                               1 \\
                              0 \\
                              \dots \\
                              0 \\
                    \end{bmatrix}.
$$

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec55">LU Decomposition, the inverse </h2>

<p>
In a similar way we can compute the unknow entries of the second column,

$$
    \mathbf{LU}\begin{bmatrix}
                              a_{12}^{-1} \\
                              a_{22}^{-1} \\
                              \dots \\
                              a_{n2}^{-1} \\
                    \end{bmatrix}=\begin{bmatrix}
                                0 \\
                              1 \\
                              \dots \\
                              0 \\
                    \end{bmatrix},
$$

and continue till we have solved all \( n \) sets of linear equations.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec56"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/cppLibrary" target="_blank">How to use the Library functions</a> </h2>

<p>
Standard C/C++: fetch the files <code>lib.cpp</code> and <code>lib.h</code>. You can make a directory where you store
these files, and eventually its compiled version lib.o. The example here is <a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/LinAlgebra/cpp/program1.cpp" target="_blank">program1.cpp from chapter 6</a> and performs the matrix inversion.

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #228B22">//  Simple matrix inversion example</span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iostream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;new&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cstdio&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cstdlib&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cmath&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;cstring&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&quot;lib.h&quot;</span><span style="color: #1e889b"></span>

<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> std;

<span style="color: #228B22">/* function declarations */</span>

<span style="color: #00688B; font-weight: bold">void</span> <span style="color: #008b45">inverse</span>(<span style="color: #00688B; font-weight: bold">double</span> **, <span style="color: #00688B; font-weight: bold">int</span>);
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec57"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/cppLibrary" target="_blank">How to use the Library functions</a> </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #00688B; font-weight: bold">void</span> <span style="color: #008b45">inverse</span>(<span style="color: #00688B; font-weight: bold">double</span> **a, <span style="color: #00688B; font-weight: bold">int</span> n)
{
  <span style="color: #00688B; font-weight: bold">int</span>          i,j, *indx;
  <span style="color: #00688B; font-weight: bold">double</span>       d, *col, **y;
  <span style="color: #228B22">// allocate space in memory</span>
  indx = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">int</span>[n];
  col  = <span style="color: #8B008B; font-weight: bold">new</span> <span style="color: #00688B; font-weight: bold">double</span>[n];
  y    = (<span style="color: #00688B; font-weight: bold">double</span> **) matrix(n, n, <span style="color: #8B008B; font-weight: bold">sizeof</span>(<span style="color: #00688B; font-weight: bold">double</span>));
  ludcmp(a, n, indx, &amp;d);   <span style="color: #228B22">// LU decompose  a[][]</span>
  printf(<span style="color: #CD5555">&quot;\n\nLU form of matrix of a[][]:\n&quot;</span>);
  <span style="color: #8B008B; font-weight: bold">for</span>(i = <span style="color: #B452CD">0</span>; i &lt; n; i++) {
    printf(<span style="color: #CD5555">&quot;\n&quot;</span>);
    <span style="color: #8B008B; font-weight: bold">for</span>(j = <span style="color: #B452CD">0</span>; j &lt; n; j++) {
      printf(<span style="color: #CD5555">&quot; a[%2d][%2d] = %12.4E&quot;</span>,i, j, a[i][j]);
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec58"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/cppLibrary" target="_blank">How to use the Library functions</a> </h2>

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  <span style="color: #228B22">// find inverse of a[][] by columns</span>
  <span style="color: #8B008B; font-weight: bold">for</span>(j = <span style="color: #B452CD">0</span>; j &lt; n; j++) {
    <span style="color: #228B22">// initialize right-side of linear equations</span>
    <span style="color: #8B008B; font-weight: bold">for</span>(i = <span style="color: #B452CD">0</span>; i &lt; n; i++) col[i] = <span style="color: #B452CD">0.0</span>;
    col[j] = <span style="color: #B452CD">1.0</span>;
    lubksb(a, n, indx, col);
    <span style="color: #228B22">// save result in y[][]</span>
    <span style="color: #8B008B; font-weight: bold">for</span>(i = <span style="color: #B452CD">0</span>; i &lt; n; i++) y[i][j] = col[i];
  }   <span style="color: #228B22">//j-loop over columns</span>
  <span style="color: #228B22">// return the inverse matrix in a[][]</span>
  <span style="color: #8B008B; font-weight: bold">for</span>(i = <span style="color: #B452CD">0</span>; i &lt; n; i++) {
    <span style="color: #8B008B; font-weight: bold">for</span>(j = <span style="color: #B452CD">0</span>; j &lt; n; j++) a[i][j] = y[i][j];

  free_matrix((<span style="color: #00688B; font-weight: bold">void</span> **) y);     <span style="color: #228B22">// release local memory</span>
  <span style="color: #8B008B; font-weight: bold">delete</span> [] col;
  <span style="color: #8B008B; font-weight: bold">delete</span> []indx;
}  <span style="color: #228B22">// End: function inverse()</span>
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec59"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/FortranLibrary" target="_blank">How to use the Library functions</a> </h2>

<p>
For Fortran users:

<p>

<!-- code=fortran (!bc fcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #8B008B; font-weight: bold">PROGRAM </span>matrix
  <span style="color: #8B008B; font-weight: bold">USE </span>constants
  <span style="color: #8B008B; font-weight: bold">USE </span>F90library
  <span style="color: #8B008B; font-weight: bold">IMPLICIT NONE</span>
  <span style="color: #228B22">!      The definition of the matrix, using dynamic allocation</span>
  <span style="color: #00688B; font-weight: bold">REAL</span>(DP), <span style="color: #8B008B; font-weight: bold">ALLOCATABLE</span>, <span style="color: #8B008B; font-weight: bold">DIMENSION</span>(:,:) <span style="color: #8B008B; font-weight: bold">::</span> a, ainv, unity
  <span style="color: #228B22">!      the determinant</span>
  <span style="color: #00688B; font-weight: bold">REAL</span>(DP) <span style="color: #8B008B; font-weight: bold">::</span> d
  <span style="color: #228B22">!      The size of the matrix</span>
  <span style="color: #00688B; font-weight: bold">INTEGER</span> <span style="color: #8B008B; font-weight: bold">::</span> n
  ....
  <span style="color: #228B22">!      Allocate now place in heap for a</span>
  <span style="color: #8B008B; font-weight: bold">ALLOCATE</span> ( a(n,n), ainv(n,n), unity(n,n) )
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec60"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/tree/master/doc/Programs/LecturePrograms/programs/FortranLibrary" target="_blank">How to use the Library functions</a> </h2>

<p>
For Fortran users:

<p>

<!-- code=fortran (!bc fcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span>  <span style="color: #8B008B; font-weight: bold">WRITE</span>(<span style="color: #B452CD">6</span>,*) <span style="color: #CD5555">&#39; The matrix before inversion&#39;</span>
  <span style="color: #8B008B; font-weight: bold">WRITE</span>(<span style="color: #B452CD">6</span>,<span style="color: #CD5555">&#39;(3F12.6)&#39;</span>) a
  ainv=a
  <span style="color: #8B008B; font-weight: bold">CALL </span>matinv (ainv, n, d)
  ....
  <span style="color: #228B22">!      get the unity matrix</span>
  unity=<span style="color: #658b00">MATMUL</span>(ainv,a)
  <span style="color: #8B008B; font-weight: bold">WRITE</span>(<span style="color: #B452CD">6</span>,*) <span style="color: #CD5555">&#39; The unity matrix&#39;</span>
  <span style="color: #8B008B; font-weight: bold">WRITE</span>(<span style="color: #B452CD">6</span>,<span style="color: #CD5555">&#39;(3F12.6)&#39;</span>) unity
  <span style="color: #228B22">!      deallocate all arrays</span>
  <span style="color: #8B008B; font-weight: bold">DEALLOCATE</span> (a, ainv, unity)
<span style="color: #8B008B; font-weight: bold">END PROGRAM </span>matrix
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec61"><a href="https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/CppQtCodesLectures/MatrixTest/main.cpp" target="_blank">Using Armadillo to perform an LU decomposition</a> </h2>
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #1e889b">#include</span> <span style="color: #228B22">&lt;iostream&gt;</span><span style="color: #1e889b"></span>
<span style="color: #1e889b">#include</span> <span style="color: #228B22">&quot;armadillo&quot;</span><span style="color: #1e889b"></span>
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> arma;
<span style="color: #8B008B; font-weight: bold">using</span> <span style="color: #8B008B; font-weight: bold">namespace</span> std;

<span style="color: #00688B; font-weight: bold">int</span> <span style="color: #008b45">main</span>()
  {
   mat A = randu&lt;mat&gt;(<span style="color: #B452CD">5</span>,<span style="color: #B452CD">5</span>);
   vec b = randu&lt;vec&gt;(<span style="color: #B452CD">5</span>);

  A.print(<span style="color: #CD5555">&quot;A =&quot;</span>);
  b.print(<span style="color: #CD5555">&quot;b=&quot;</span>);
  <span style="color: #228B22">// solve Ax = b</span>
  vec x = solve(A,b);
  <span style="color: #228B22">// print x</span>
  x.print(<span style="color: #CD5555">&quot;x=&quot;</span>);
  <span style="color: #228B22">// find LU decomp of A, if needed, P is the permutation matrix</span>
  mat L, U;
  lu(L,U,A);
  <span style="color: #228B22">// print l</span>
  L.print(<span style="color: #CD5555">&quot; L= &quot;</span>);
  <span style="color: #228B22">// print U</span>
  U.print(<span style="color: #CD5555">&quot; U= &quot;</span>);
  <span style="color: #228B22">//Check that A = LU</span>
  (A-L*U).print(<span style="color: #CD5555">&quot;Test of LU decomposition&quot;</span>);
    <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #B452CD">0</span>;
  }
</pre></div>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec62">Iterative methods, Chapter 6 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>

<ul>
 <li> Direct solvers such as Gauss elimination and  LU decomposition discussed in connection with project 1.</li>
 <li> Iterative solvers such as Basic iterative solvers,  Jacobi,  Gauss-Seidel, Successive over-relaxation. These methods are easy to parallelize, as we will se later. Much used in solutions of partial differential equations.</li>
 <li> Other iterative methods such as Krylov subspace methods with Generalized minimum residual (GMRES) and Conjugate gradient etc will not be discussed.</li>
</ul>
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec63">Iterative methods, Jacobi's method </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
It is a simple method for solving
$$ 
\mathbf{A}\mathbf{x}=\mathbf{b},
$$

where \( \mathbf{A} \) is a matrix and \( \mathbf{x} \) and \( \mathbf{b} \) are vectors. The vector \( \mathbf{x} \) is 
the unknown.

<p>
It is an iterative scheme where we start with a guess for the unknown, and 
after \( k+1 \) iterations we have  
$$ 
\mathbf{x}^{(k+1)}= \mathbf{D}^{-1}(\mathbf{b}-(\mathbf{L}+\mathbf{U})\mathbf{x}^{(k)}),
$$

with \( \mathbf{A}=\mathbf{D}+\mathbf{U}+\mathbf{L} \) and
\( \mathbf{D} \) being a diagonal matrix, \( \mathbf{U} \) an upper triangular matrix and \( \mathbf{L} \) a  lower triangular
matrix.

<p>
If the matrix \( \mathbf{A} \) is positive definite or diagonally dominant, one can show that this method will always converge to the exact solution.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec64">Iterative methods, Jacobi's method </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
We can demonstrate Jacobi's method by this \( 4\times 4 \) matrix problem. We assume a guess
for the vector elements \( x_i^{(0)} \), a guess which represents our first iteration. The new
values are obtained by substitution
$$
\begin{align}
 x_1^{(1)} =&(b_1-a_{12}x_2^{(0)} -a_{13}x_3^{(0)} - a_{14}x_4^{(0)})/a_{11} \nonumber \\
 x_2^{(1)} =&(b_2-a_{21}x_1^{(0)} - a_{23}x_3^{(0)} - a_{24}x_4^{(0)})/a_{22} \nonumber \\
 x_3^{(1)} =&(b_3- a_{31}x_1^{(0)} -a_{32}x_2^{(0)} -a_{34}x_4^{(0)})/a_{33} \nonumber \\
 x_4^{(1)}=&(b_4-a_{41}x_1^{(0)} -a_{42}x_2^{(0)} - a_{43}x_3^{(0)})/a_{44},  \nonumber
\end{align}
$$

which after \( k+1 \) iterations reads
$$
\begin{align}
 x_1^{(k+1)} =&(b_1-a_{12}x_2^{(k)} -a_{13}x_3^{(k)} - a_{14}x_4^{(k)})/a_{11} \nonumber \\
 x_2^{(k+1)} =&(b_2-a_{21}x_1^{(k)} - a_{23}x_3^{(k)} - a_{24}x_4^{(k)})/a_{22} \nonumber \\
 x_3^{(k+1)} =&(b_3- a_{31}x_1^{(k)} -a_{32}x_2^{(k)} -a_{34}x_4^{(k)})/a_{33} \nonumber \\
 x_4^{(k+1)}=&(b_4-a_{41}x_1^{(k)} -a_{42}x_2^{(k)} - a_{43}x_3^{(k)})/a_{44},  \nonumber
\end{align}
$$
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec65">Iterative methods, Jacobi's method </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
We can generalize the above equations to
$$
 x_i^{(k+1)}=(b_i-\sum_{j=1, j\ne i}^{n}a_{ij}x_j^{(k)})/a_{ii}
$$

or in an even more compact form as
$$ \mathbf{x}^{(k+1)}= \mathbf{D}^{-1}(\mathbf{b}-(\mathbf{L}+\mathbf{U})\mathbf{x}^{(k)}),
$$

with \( \mathbf{A}=\mathbf{D}+\mathbf{U}+\mathbf{L} \) and
\( \mathbf{D} \) being a diagonal matrix, \( \mathbf{U} \) an upper triangular matrix and \( \mathbf{L} \) a  lower triangular
matrix.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec66">Iterative methods, Gauss-Seidel's method </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Our \( 4\times 4 \) matrix problem 
$$
\begin{align}
 x_1^{(k+1)} =&(b_1-a_{12}x_2^{(k)} -a_{13}x_3^{(k)} - a_{14}x_4^{(k)})/a_{11} \nonumber \\
 x_2^{(k+1)} =&(b_2-a_{21}x_1^{(k)} - a_{23}x_3^{(k)} - a_{24}x_4^{(k)})/a_{22} \nonumber \\
 x_3^{(k+1)} =&(b_3- a_{31}x_1^{(k)} -a_{32}x_2^{(k)} -a_{34}x_4^{(k)})/a_{33} \nonumber \\
 x_4^{(k+1)}=&(b_4-a_{41}x_1^{(k)} -a_{42}x_2^{(k)} - a_{43}x_3^{(k)})/a_{44},  \nonumber
\end{align}
$$

can be rewritten as 
$$
\begin{align}
 x_1^{(k+1)} =&(b_1-a_{12}x_2^{(k)} -a_{13}x_3^{(k)} - a_{14}x_4^{(k)})/a_{11} \nonumber \\
 x_2^{(k+1)} =&(b_2-a_{21}x_1^{(k+1)} - a_{23}x_3^{(k)} - a_{24}x_4^{(k)})/a_{22} \nonumber \\
 x_3^{(k+1)} =&(b_3- a_{31}x_1^{(k+1)} -a_{32}x_2^{(k+1)} -a_{34}x_4^{(k)})/a_{33} \nonumber \\
 x_4^{(k+1)}=&(b_4-a_{41}x_1^{(k+1)} -a_{42}x_2^{(k+1)} - a_{43}x_3^{(k+1)})/a_{44},  \nonumber
\end{align}
$$

which allows us to utilize the preceding solution (forward substitution). This improves normally the convergence
behavior and leads to the Gauss-Seidel method!
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec67">Iterative methods, Gauss-Seidel's method </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
We can generalize 
$$
\begin{align}
 x_1^{(k+1)} =&(b_1-a_{12}x_2^{(k)} -a_{13}x_3^{(k)} - a_{14}x_4^{(k)})/a_{11} \nonumber \\
 x_2^{(k+1)} =&(b_2-a_{21}x_1^{(k+1)} - a_{23}x_3^{(k)} - a_{24}x_4^{(k)})/a_{22} \nonumber \\
 x_3^{(k+1)} =&(b_3- a_{31}x_1^{(k+1)} -a_{32}x_2^{(k+1)} -a_{34}x_4^{(k)})/a_{33} \nonumber \\
 x_4^{(k+1)}=&(b_4-a_{41}x_1^{(k+1)} -a_{42}x_2^{(k+1)} - a_{43}x_3^{(k+1)})/a_{44},  \nonumber
\end{align}
$$

to the following form
$$
 x^{(k+1)}_i = \frac{1}{a_{ii}} \left(b_i - \sum_{j > i}a_{ij}x^{(k)}_j - \sum_{j < i}a_{ij}x^{(k+1)}_j \right),\quad i=1,2,\ldots,n. 
$$

The procedure is generally continued until the changes made by an iteration are below some tolerance.

<p>
The convergence properties of the Jacobi method and the 
Gauss-Seidel method are dependent on the matrix \( \mathbf{A} \). These methods converge when
the matrix is symmetric positive-definite, or is strictly or irreducibly diagonally dominant.
Both methods sometimes converge even if these conditions are not satisfied.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec68">Iterative methods, Successive over-relaxation </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Given a square system of n linear equations with unknown \( \mathbf x \):
$$
    \mathbf{A}\mathbf x = \mathbf b
$$

where
$$
    \mathbf{A}=\begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix}, \qquad \mathbf{x} = \begin{bmatrix} x_{1} \\ x_2 \\ \vdots \\ x_n \end{bmatrix} , \qquad \mathbf{b} = \begin{bmatrix} b_{1} \\ b_2 \\ \vdots \\ b_n \end{bmatrix}.
$$
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec69">Iterative methods, Successive over-relaxation </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Then A can be decomposed into a diagonal component D, and strictly lower and upper triangular components L and U:
$$
    \mathbf{A} =\mathbf{D} + \mathbf{L} + \mathbf{U},
$$

where
$$
    D = \begin{bmatrix} a_{11} & 0 & \cdots & 0 \\ 0 & a_{22} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & a_{nn} \end{bmatrix}, \quad L = \begin{bmatrix} 0 & 0 & \cdots & 0 \\ a_{21} & 0 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\a_{n1} & a_{n2} & \cdots & 0 \end{bmatrix}, \quad U = \begin{bmatrix} 0 & a_{12} & \cdots & a_{1n} \\ 0 & 0 & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\0 & 0 & \cdots & 0 \end{bmatrix}. 
$$

The system of linear equations may be rewritten as:
$$
    (D+\omega L) \mathbf{x} = \omega \mathbf{b} - [\omega U + (\omega-1) D ] \mathbf{x} 
$$

for a constant \( \omega > 1 \).
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec70">Iterative methods, Successive over-relaxation </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
The method of successive over-relaxation is an iterative technique that solves the left hand side of this expression for \( x \), using previous value for \( x \) on the right hand side. Analytically, this may be written as:
$$
    \mathbf{x}^{(k+1)} = (D+\omega L)^{-1} \big(\omega \mathbf{b} - [\omega U + (\omega-1) D ] \mathbf{x}^{(k)}\big). 
$$

However, by taking advantage of the triangular form of \( (D+\omega L) \), the elements of \( x^{(k+1)} \) can be computed sequentially using forward substitution:
$$
    x^{(k+1)}_i = (1-\omega)x^{(k)}_i + \frac{\omega}{a_{ii}} \left(b_i - \sum_{j > i} a_{ij}x^{(k)}_j - \sum_{j < i} a_{ij}x^{(k+1)}_j \right),\quad i=1,2,\ldots,n. 
$$

The choice of relaxation factor is not necessarily easy, and depends upon the properties of the coefficient matrix. For symmetric, positive-definite matrices it can be proven that \( 0 < \omega < 2 \) will lead to convergence, but we are generally interested in faster convergence rather than just convergence.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec71">Cubic Splines, Chapter 6 </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Cubic spline interpolation is among one of the most used 
methods for interpolating between data points where the arguments
are organized as ascending series. In the library program we supply
such a function, based on the so-called cubic spline method to be 
described below.

<p>
A spline function consists of polynomial pieces defined on
subintervals. The different subintervals are connected via
various continuity relations.

<p>
Assume we have at our disposal \( n+1 \) points \( x_0, x_1, \dots x_n \) 
arranged so that \( x_0 < x_1 < x_2 < \dots x_{n-1} < x_n \) (such points are called
knots). A spline function \( s \) of degree \( k \) with \( n+1 \) knots is defined
as follows

<ul>
 <li> On every subinterval \( [x_{i-1},x_i) \) <em>s</em> is a polynomial of degree \( \le k \).</li>
 <li> \( s \) has \( k-1 \) continuous derivatives in the whole interval \( [x_0,x_n] \).</li>
</ul>
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec72">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
As an example, consider a spline function of degree \( k=1 \) defined as follows
$$
    s(x)=\begin{bmatrix} s_0(x)=a_0x+b_0 & x\in [x_0, x_1) \\   
                             s_1(x)=a_1x+b_1 & x\in [x_1, x_2) \\   
                             \dots & \dots \\
                             s_{n-1}(x)=a_{n-1}x+b_{n-1} & x\in 
                             [x_{n-1}, x_n] \end{bmatrix}.
$$

In this case the polynomial consists of series of straight lines 
connected to each other at every endpoint. The number of continuous
derivatives is then \( k-1=0 \), as expected when we deal with straight lines.
Such a polynomial is quite easy to construct given
\( n+1 \) points \( x_0, x_1, \dots x_n \) and their corresponding 
function values.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec73">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
The most commonly used spline function is the one with \( k=3 \), the so-called
cubic spline function. 
Assume that we have in adddition to the \( n+1 \) knots a series of
functions values \( y_0=f(x_0), y_1=f(x_1), \dots y_n=f(x_n) \).
By definition, the polynomials \( s_{i-1} \) and \( s_i \) 
are thence supposed to interpolate the same point \( i \), that is
$$
    s_{i-1}(x_i)= y_i = s_i(x_i),
$$

with \( 1 \le i \le n-1 \). In total we have \( n \) polynomials of the 
type
$$
    s_i(x)=a_{i0}+a_{i1}x+a_{i2}x^2+a_{i2}x^3,
$$

yielding \( 4n \) coefficients to determine.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec74">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Every subinterval provides in addition the \( 2n \) conditions 
$$
    y_i = s(x_i),
$$

and 
$$
    s(x_{i+1})= y_{i+1},
$$

to be fulfilled. If we also assume that \( s' \) and \( s'' \) are continuous,
then
$$
       s'_{i-1}(x_i)= s'_i(x_i),
$$

yields \( n-1 \) conditions. Similarly,
$$
       s''_{i-1}(x_i)= s''_i(x_i),
$$

results in additional \( n-1 \) conditions. In total we have \( 4n \) coefficients
and \( 4n-2 \) equations to determine them, leaving us with \( 2 \) degrees of 
freedom to be determined.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec75">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Using the last equation we define two values for the second derivative, namely
$$
       s''_{i}(x_i)= f_i,
$$

and
$$
       s''_{i}(x_{i+1})= f_{i+1},
$$

and setting up a straight line between \( f_i \) and \( f_{i+1} \) we have
$$
   s_i''(x) = \frac{f_i}{x_{i+1}-x_i}(x_{i+1}-x)+
               \frac{f_{i+1}}{x_{i+1}-x_i}(x-x_i),
$$

and integrating twice one obtains
$$
   s_i(x) = \frac{f_i}{6(x_{i+1}-x_i)}(x_{i+1}-x)^3+
               \frac{f_{i+1}}{6(x_{i+1}-x_i)}(x-x_i)^3
             +c(x-x_i)+d(x_{i+1}-x).
$$
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec76">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Using the conditions \( s_i(x_i)=y_i \) and \( s_i(x_{i+1})=y_{i+1} \) 
we can in turn determine the constants \( c \) and \( d \) resulting in
$$
\begin{align}
   s_i(x) =&\frac{f_i}{6(x_{i+1}-x_i)}(x_{i+1}-x)^3+
               \frac{f_{i+1}}{6(x_{i+1}-x_i)}(x-x_i)^3 \nonumber  \\ 
            +&(\frac{y_{i+1}}{x_{i+1}-x_i}-\frac{f_{i+1}(x_{i+1}-x_i)}{6})
              (x-x_i)+
             (\frac{y_{i}}{x_{i+1}-x_i}-\frac{f_{i}(x_{i+1}-x_i)}{6})
             (x_{i+1}-x).
\label{_auto13}
\end{align}
$$
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec77">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
How to determine the values of the second
derivatives \( f_{i} \) and \( f_{i+1} \)? We use the continuity assumption 
of the first derivatives 
$$
    s'_{i-1}(x_i)= s'_i(x_i),
$$

and set \( x=x_i \). Defining \( h_i=x_{i+1}-x_i \) we obtain finally
the following expression
$$
   h_{i-1}f_{i-1}+2(h_{i}+h_{i-1})f_i+h_if_{i+1}=
   \frac{6}{h_i}(y_{i+1}-y_i)-\frac{6}{h_{i-1}}(y_{i}-y_{i-1}),
$$

and introducing the shorthands \( u_i=2(h_{i}+h_{i-1}) \), 
\( v_i=\frac{6}{h_i}(y_{i+1}-y_i)-\frac{6}{h_{i-1}}(y_{i}-y_{i-1}) \),
we can reformulate the problem as a set of linear equations to be 
solved  through e.g., Gaussian elemination
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec78">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Gaussian elimination
$$
   \begin{bmatrix} u_1 & h_1 &0 &\dots & & & & \\
                                 h_1 & u_2 & h_2 &0 &\dots & & & \\
                                  0   & h_2 & u_3 & h_3 &0 &\dots & & \\
                               \dots& & \dots &\dots &\dots &\dots &\dots & \\
                                 &\dots & & &0 &h_{n-3} &u_{n-2} &h_{n-2} \\
                                 & && & &0 &h_{n-2} &u_{n-1} \end{bmatrix}
   \begin{bmatrix} f_1 \\ 
                          f_2 \\
                          f_3\\
                          \dots \\
                          f_{n-2} \\ 
                          f_{n-1} \end{bmatrix} =
   \begin{bmatrix} v_1 \\ 
                          v_2 \\
                          v_3\\
                          \dots \\
                          v_{n-2}\\
                          v_{n-1} \end{bmatrix}.
$$

Note that this is a set of tridiagonal equations and can be solved 
through only \( O(n) \) operations.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec79">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
The functions supplied in the program library are <em>spline</em> and <em>splint</em>.
In order to use cubic spline interpolation you need first to call

<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>spline(<span style="color: #00688B; font-weight: bold">double</span> x[], <span style="color: #00688B; font-weight: bold">double</span> y[], <span style="color: #00688B; font-weight: bold">int</span> n, <span style="color: #00688B; font-weight: bold">double</span> yp1,  <span style="color: #00688B; font-weight: bold">double</span> yp2, <span style="color: #00688B; font-weight: bold">double</span> y2[])
</pre></div>
<p>
This function takes as
input \( x[0,..,n - 1] \) and \( y[0,..,n - 1] \) containing a tabulation
\( y_i = f(x_i) \) with \( x_0 < x_1 < .. < x_{n - 1} \) 
together with the 
first derivatives  of \( f(x) \) at \( x_0 \) and \( x_{n-1} \), respectively. Then the
function returns \( y2[0,..,n-1] \) which contains the second derivatives of
\( f(x_i) \) at each point \( x_i \). \( n \) is the number of points.
This function provides the cubic spline interpolation for all subintervals
and is called only once.
</div>


<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec80">Splines </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
Thereafter, if you wish to make  various interpolations, you need to call the function 
<p>

<!-- code=c++ (!bc cppcod) typeset with pygments style "perldoc" -->
<div class="highlight" style="background: #eee8d5"><pre style="line-height: 125%"><span></span>splint(<span style="color: #00688B; font-weight: bold">double</span> x[], <span style="color: #00688B; font-weight: bold">double</span> y[], <span style="color: #00688B; font-weight: bold">double</span> y2a[], <span style="color: #00688B; font-weight: bold">int</span> n, <span style="color: #00688B; font-weight: bold">double</span> x, <span style="color: #00688B; font-weight: bold">double</span> *y)
</pre></div>
<p>
which takes as input
the tabulated values \( x[0,..,n - 1] \) and \( y[0,..,n - 1] \) and the output 
y2a[0,..,n - 1] from <em>spline</em>. It returns the value \( y \) corresponding
to the point \( x \).
</div>


<!-- ------------------- end of main content --------------- -->


<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2018, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>


</body>
</html>
    

